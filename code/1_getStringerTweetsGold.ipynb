{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_getStringerTweetsGold.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9cE7UgNS8pZJ"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8wN8h7rpkK1"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cE7UgNS8pZJ"
      },
      "source": [
        "### user input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGagAdKFKAOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1cc026d-f7bb-4022-8819-7c428bc9c158"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "# drive = 'drive/My Drive/Spring 2021/Stringer/Data/'\n",
        "drive = '/content/drive/MyDrive/Stringer/Data/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nq9Hgq4ok2I"
      },
      "source": [
        "# # Twitter key\n",
        "# ACCESS_TOKEN = \n",
        "# ACCESS_TOKEN_SECRET = \n",
        "# CONSUMER_KEY = \n",
        "# CONSUMER_SECRET = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWvOpgd2rdZK"
      },
      "source": [
        "# code to ingest user input and then turn it into list of search terms\n",
        "\n",
        "# searchTerm = [x for x in input(\"Please enter a list of query terms\\n\").split(', ')]\n",
        "# print(\"\\nInput Values: \", searchTerm) # vaccine, covid, coronavirus, pfizer, moderna, astrazenica, johnson, jab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL4cLq2zfQUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7475b565-7a32-455c-c62f-96b611cb4375"
      },
      "source": [
        "# enter in query requirements, number of tweets, user, etc. \n",
        "startDate = '2021-04-24'\n",
        "endDate = '2021-04-25' \n",
        "# searchTerm = ['vaccine', 'covid']\n",
        "searchTerm = ['vaccine', 'covid', 'coronavirus', 'pfizer', 'moderna', 'astrazenica', 'johnson', 'jab']\n",
        "\n",
        "numTweets = 15000\n",
        "# Please change to reflect user \n",
        "user = 'RHI' #PS #KE #RHI #FP \n",
        "\n",
        "def timeStamped(fname, fmt='%Y-%m-%d-%H-%M-%S-{fname}'):\n",
        "        import datetime\n",
        "        return datetime.datetime.now().strftime(fmt).format(fname=fname)\n",
        "\n",
        "outputFile = timeStamped(f'{user}_{numTweets}') + '_' + startDate\n",
        "print(outputFile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-01-23-52-42-RHI_15000_2021-04-24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVBzyNOvoiNg"
      },
      "source": [
        "#### packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIP0NNmEohPG",
        "outputId": "6e509ac8-fbba-4d19-cadd-d541bdb6bec5"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "\n",
        "!pip install tweepy\n",
        "import tweepy\n",
        "\n",
        "import csv\n",
        "\n",
        "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
        "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "\n",
        "# create API object\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/c9/b413a24f759641bc27ef98c144b590023c8038dfb8a3f09e713e9dff12c1/ipython_autotime-0.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.0.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (56.0.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
            "time: 2.73 s (started: 2021-05-01 23:52:48 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYhRIRMnlATU"
      },
      "source": [
        "### option 1: search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B0XZfYBHpUxQ",
        "outputId": "851d5815-dfc4-438c-e049-37a06d5db959"
      },
      "source": [
        "# edit user input so that it works with twitter search\n",
        "# https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/guides/standard-operators \n",
        "searchTermStr = str(searchTerm).replace(',', ' OR')\n",
        "searchTermStr = re.sub(\"'|\\[|\\]\", '', searchTermStr)\n",
        "searchTermStr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'vaccine OR covid OR coronavirus OR pfizer OR moderna OR astrazenica OR johnson OR jab'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "stream",
          "text": [
            "time: 6.9 ms (started: 2021-05-01 23:53:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWvghMQ7jlQh",
        "outputId": "b9ef4650-fab7-483b-b764-48bed29f53e0"
      },
      "source": [
        "# choose features and save to file\n",
        "outputPath = str(outputFile + '_search' + '.csv')\n",
        "\n",
        "tweets = tweepy.Cursor(api.search, q=searchTermStr, tweet_mode = 'extended', lang='en', since=startDate, until=endDate, wait_on_rate_limit=True).items(numTweets)\n",
        "# tweets = tweepy.Cursor(api.search, q=searchTermStr, tweet_mode = 'extended', lang='en', wait_on_rate_limit=True).items(numTweets) #, since=startDate, until=endDate)\n",
        "tweetLst = []\n",
        "i = 0\n",
        "for tweet in tweets:\n",
        "  if i % 500 == 0:\n",
        "    print(i, 'tweets so far')\n",
        "\n",
        "  if hasattr(tweet, 'retweeted_status'):  # Check if Retweet\n",
        "    try:\n",
        "      tweetLst.append([tweet.id_str, tweet.author.screen_name, tweet.created_at, tweet.retweeted_status.extended_tweet[\"full_text\"], tweet.favorite_count, tweet.retweet_count, tweet.user.description, tweet.user.verified, tweet.user.followers_count, 1, [i['text'] for i in tweet.entities['hashtags']]])\n",
        "      # print(tweet.retweeted_status.extended_tweet[\"full_text\"], '\\n', [i['text'] for i in tweet.entities['hashtags']])\n",
        "    except:\n",
        "      tweetLst.append([tweet.id_str, tweet.author.screen_name, tweet.created_at, tweet.retweeted_status.full_text, tweet.favorite_count, tweet.retweet_count, tweet.user.description, tweet.user.verified, tweet.user.followers_count, 1, [i['text'] for i in tweet.entities['hashtags']]])\n",
        "      # tweetLst.append([tweet.id_str, tweet.author.screen_name, tweet.created_at, tweet.retweeted_status.text, tweet.favorite_count, tweet.user.description, tweet.user.verified, tweet.user.followers_count, 1, [i['text'] for i in tweet.entities['hashtags']]])\n",
        "      # print(tweet.retweeted_status.text, '\\n', [i['text'] for i in tweet.entities['hashtags']])\n",
        "  else:\n",
        "    try:\n",
        "      tweetLst.append([tweet.id_str, tweet.author.screen_name, tweet.created_at, tweet.extended_tweet[\"full_text\"], tweet.favorite_count, tweet.retweet_count, tweet.user.description, tweet.user.verified, tweet.user.followers_count, 1, [i['text'] for i in tweet.entities['hashtags']]])\n",
        "      # print(tweet.extended_tweet[\"full_text\"], '\\n', [i['text'] for i in tweet.entities['hashtags']])\n",
        "    except:\n",
        "      tweetLst.append([tweet.id_str, tweet.author.screen_name, tweet.created_at, tweet.full_text, tweet.favorite_count, tweet.retweet_count, tweet.user.description, tweet.user.verified, tweet.user.followers_count, 1, [i['text'] for i in tweet.entities['hashtags']]])\n",
        "      # tweetLst.append([tweet.id_str, tweet.author.screen_name, tweet.created_at, tweet.text, tweet.favorite_count, tweet.user.description, tweet.user.verified, tweet.user.followers_count, 1, [i['text'] for i in tweet.entities['hashtags']]])\n",
        "      # print(tweet.text, '\\n', [i['text'] for i in tweet.entities['hashtags']])\n",
        "  if hasattr(tweet, 'quoted_status'):   # Check if Quote tweet\n",
        "    # if hasattr(tweet.quoted_status) #, 'extended_tweet'):\n",
        "    # tweetLst.append([1, tweet.quoted_status.extended_tweet['full_text']]) #[status.quoted_status_id, tweet_mode='extended'])\n",
        "  # else:\n",
        "    tweetLst[i].extend([1, tweet.quoted_status.full_text])\n",
        "  else:\n",
        "    tweetLst[i].extend([0, 'None'])\n",
        "  i +=1\n",
        "print(len(tweetLst), tweetLst[:10])\n",
        "\n",
        "with open(outputPath, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['tweet_id', 'user', 'created_on', 'tweet_text', 'fav_count', 'retweet_count', 'user_description', 'user_verified', 'user_follower_count', 'is_retweet', 'hashtags', 'is_quote', 'quote_text'])\n",
        "    writer.writerows(tweetLst)\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tweets so far\n",
            "500 tweets so far\n",
            "1000 tweets so far\n",
            "1500 tweets so far\n",
            "2000 tweets so far\n",
            "2500 tweets so far\n",
            "3000 tweets so far\n",
            "3500 tweets so far\n",
            "4000 tweets so far\n",
            "4500 tweets so far\n",
            "5000 tweets so far\n",
            "5500 tweets so far\n",
            "6000 tweets so far\n",
            "6500 tweets so far\n",
            "7000 tweets so far\n",
            "7500 tweets so far\n",
            "8000 tweets so far\n",
            "8500 tweets so far\n",
            "9000 tweets so far\n",
            "9500 tweets so far\n",
            "10000 tweets so far\n",
            "10500 tweets so far\n",
            "11000 tweets so far\n",
            "11500 tweets so far\n",
            "12000 tweets so far\n",
            "12500 tweets so far\n",
            "13000 tweets so far\n",
            "13500 tweets so far\n",
            "14000 tweets so far\n",
            "14500 tweets so far\n",
            "15000 [['1386107687465848835', 'NoohpotoFarooq', datetime.datetime(2021, 4, 24, 23, 59, 59), 'Emergency Meeting On Current Situation Of Covid-19 Outbreak. \\nLocals Are Requested To Follow SOPs To Get Rid Of Deadly Virus.\\nDate :- 25-04-2021\\nTime :- 12:30 AM \\n#COVID19outbreak\\nHere is @lalajaffar45 \\nDHO Hyderabad\\nHats off to His Struggle and his teams work\\nMore Power to them https://t.co/RMQemNVg7F', 0, 26, 'political activist & # Team ppp_Matiari', False, 1474, 1, [], 0, 'None'], ['1386107686865936386', 'vup11vaishali', datetime.datetime(2021, 4, 24, 23, 59, 59), '@malhar_pandey @be_rose_gaar ‡§Ö‡§ó‡§¶‡•Ä ‡§¨‡§∞‡•ã‡§¨‡§∞ ... we are also going to pay if necessary for our society helpers and our own house maids for vaccine', 0, 0, '', False, 13, 1, [], 0, 'None'], ['1386107686631219201', 'yagamis4rah', datetime.datetime(2021, 4, 24, 23, 59, 59), 'and then when we have the 2822929th covid wave and discover 40 more viral mutationsüíñ https://t.co/PQbPB57cwE', 5, 0, 'this strong ass sprite', False, 161, 1, [], 1, 'They DID It ! They actually did it ! Battle of Josh https://t.co/gmT2SkW89u'], ['1386107686501113858', 'mattprescott', datetime.datetime(2021, 4, 24, 23, 59, 59), 'Boris JOHNSON, Richard DESMOND https://t.co/LqPwEHNHoi', 6, 3, 'Oxford PhD (DPhil) in Zoology, Founder Environmental Rating Agency and Ban The Bulb, @BanCoalOrg @ProDemocracyUK  \\n#TrumpBrexitRussia network analysis', False, 14718, 1, [], 1, \". @BorisJohnson Doesn't like this picture either. Saving his Porn Baron friend Richard Desmond ¬£45million. üè¥\\u200d‚ò†Ô∏è https://t.co/C0rSdX1M6f\"], ['1386107686446587906', 'Eltornadito', datetime.datetime(2021, 4, 24, 23, 59, 59), 'WBC ordered Javier Fortuna and Luke Campbell to fight for the Interim Lightweight title: Fight called off due to the pandemic.\\n\\nJorge Linares withdraw due to testing positive for Covid.\\n\\nNow Ryan Garcia withdraw due to personal reasons.\\n\\nFortuna has the worst luck in boxing.', 0, 31, 'https://t.co/shHQJIYykO', False, 10369, 1, [], 0, 'None'], ['1386107686035484673', 'pramodk36324489', datetime.datetime(2021, 4, 24, 23, 59, 59), '@POTUS America has been quicker to supply weapons to Al Qaeda laced rebels for regime change than oxygen to foreign governments in the fight against Covid.', 1, 0, 'I am a civil engineer', False, 10, 1, [], 0, 'None'], ['1386107686031331336', 'Sahira_Wani', datetime.datetime(2021, 4, 24, 23, 59, 59), 'Today India has become such a Vishwa Guru that USA has denied us Raw Material for vaccine &amp; Pakistan is offering us help.\\nThank You Modi ji.', 0, 596, 'You never lose friends. You just discover who your real friends are.', False, 993, 1, [], 0, 'None'], ['1386107685418962945', 'ANGELSandWAR', datetime.datetime(2021, 4, 24, 23, 59, 59), 'Delhi residents take matter into their own hands and have resorted to buying their own oxygen as the hospitals run low on supplies #india #coronavirus #oxygen https://t.co/TrhFCAytv6', 0, 407, 'philozoic...üåπ', False, 239, 1, [], 0, 'None'], ['1386107684999639040', 'mogowxx', datetime.datetime(2021, 4, 24, 23, 59, 59), 'Please join me and send a message to France‚Äôs @EmmanuelMacron and other #G7 leaders asking them to pledge dollars or doses to help everyone around the world fight the COVID-19 pandemic. #VaxLive', 0, 4081, '‚úùÔ∏è üáªüá¶üá∑üá™üáÆüá≥üá´üá∑ //üá¶üá≤ ___________________________________________ Jeune maman Chr√©tienne Catholique üôèüèΩüíï     * LLL allaitement, Cododo, DME, maternage \\U0001f90d', False, 580, 1, ['G7'], 0, 'None'], ['1386107684470935554', 'Bonan_Me', datetime.datetime(2021, 4, 24, 23, 59, 59), 'India asks Twitter to take down some tweets critical of its COVID-19 handling https://t.co/PJrP1NwySx https://t.co/HHWlU4znkA', 0, 411, '', False, 122, 1, [], 0, 'None']]\n",
            "Done\n",
            "time: 1h 16min 23s (started: 2021-05-01 23:53:24 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8jdaioVd1mj"
      },
      "source": [
        "### option 2: stream listener"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8RBxIyMAkks",
        "outputId": "0e9a492e-e875-4228-e320-4a003a56062e"
      },
      "source": [
        "# https://developer.twitter.com/en/docs/twitter-api/v1/tweets/filter-realtime/overview"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.05 ms (started: 2021-04-01 13:29:28 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_QoRl509pqR",
        "outputId": "50fdd9e7-6ae2-42fc-824f-0c53ea9f132a"
      },
      "source": [
        "# choose features and save data\n",
        "outputPath = str(drive + '/streamListenerRaw/' + outputFile + '_streamlistener' + '.csv')\n",
        "\n",
        "class CustomStreamListener(tweepy.StreamListener):\n",
        "    def __init__(self, api=None):\n",
        "      super(CustomStreamListener, self).__init__()  \n",
        "      self.num_tweets = 0\n",
        "\n",
        "    def on_status(self, status):\n",
        "        #record = {'Text': status.text, 'Created At': status.created_at}\n",
        "        #print('record:', record)\n",
        "        self.num_tweets += 1\n",
        "        \n",
        "        #this is where you dictate the number of tweets for streamlistener\n",
        "        if self.num_tweets < 10000:\n",
        "          \n",
        "       \n",
        "          if hasattr(status, \"retweeted_status\"):  # Check if Retweet\n",
        "            try:\n",
        "              if hasattr(status, 'quoted_status'):   # Check if Quote tweet\n",
        "                try:\n",
        "                  print(status.retweeted_status.extended_tweet[\"full_text\"], '\\n', [i['text'] for i in status.entities['hashtags']], status.quoted_status.full_text)\n",
        "\n",
        "                  # Writing status data\n",
        "                  with open(outputPath, 'a') as f:\n",
        "                    writer = csv.writer(f) #, quotechar = \"'\")\n",
        "                    writer.writerow([status.id_str, status.author.screen_name, status.created_at, status.retweeted_status.extended_tweet[\"full_text\"], status.favorite_count, status.user.description, status.user.verified, status.user.followers_count, 1, [i['text'] for i in status.entities['hashtags']], 1, status.quoted_status.full_text])\n",
        "\n",
        "                except:\n",
        "                  print(status.retweeted_status.extended_tweet[\"full_text\"], '\\n', [i['text'] for i in status.entities['hashtags']], 'None')\n",
        "\n",
        "                  # Writing status data\n",
        "                  with open(outputPath, 'a') as f:\n",
        "                    writer = csv.writer(f) #, quotechar = \"'\")\n",
        "                    writer.writerow([status.id_str, status.author.screen_name, status.created_at, status.retweeted_status.extended_tweet[\"full_text\"], status.favorite_count, status.user.description, status.user.verified, status.user.followers_count, 1, [i['text'] for i in status.entities['hashtags']], 0, 'None'])\n",
        "              \n",
        "            except AttributeError:\n",
        "              if hasattr(status, 'quoted_status'):   # Check if Quote tweet\n",
        "                try:\n",
        "                  print(status.retweeted_status.text, '\\n', [i['text'] for i in status.entities['hashtags']], status.quoted_status.full_text)\n",
        "                  \n",
        "                  # Writing status data\n",
        "                  with open(outputPath, 'a') as f:\n",
        "                    writer = csv.writer(f) #, quotechar = \"'\")\n",
        "                    writer.writerow([status.id_str, status.author.screen_name, status.created_at, status.retweeted_status.text, status.favorite_count, status.user.description, status.user.verified, status.user.followers_count, 1, [i['text'] for i in status.entities['hashtags']], 1, status.quoted_status.full_text])\n",
        "\n",
        "                except:\n",
        "                  print(status.retweeted_status.text, '\\n', [i['text'] for i in status.entities['hashtags']], 'None')\n",
        "                  \n",
        "                  # Writing status data\n",
        "                  with open(outputPath, 'a') as f:\n",
        "                    writer = csv.writer(f) #, quotechar = \"'\")\n",
        "                    writer.writerow([status.id_str, status.author.screen_name, status.created_at, status.retweeted_status.text, status.favorite_count, status.user.description, status.user.verified, status.user.followers_count, 1, [i['text'] for i in status.entities['hashtags']], 0, 'None'])\n",
        "\n",
        "          else:\n",
        "            try:\n",
        "              if hasattr(status, 'quoted_status'):   # Check if Quote tweet\n",
        "                try:\n",
        "                  print(status.extended_tweet[\"full_text\"], '\\n', [i['text'] for i in status.entities['hashtags']], status.quoted_status.full_text)\n",
        "                  \n",
        "                  # Writing status data\n",
        "                  with open(outputPath, 'a') as f:\n",
        "                    writer = csv.writer(f) #, quotechar = \"'\")\n",
        "                    writer.writerow([status.id_str, status.author.screen_name, status.created_at, status.extended_tweet[\"full_text\"], status.favorite_count, status.user.description, status.user.verified, status.user.followers_count, 0, [i['text'] for i in status.entities['hashtags']], 1, status.quoted_status.full_text])\n",
        "                \n",
        "                except:\n",
        "                  print(status.extended_tweet[\"full_text\"], '\\n', [i['text'] for i in status.entities['hashtags']], 'None')             \n",
        "                  \n",
        "                  # Writing status data\n",
        "                  with open(outputPath, 'a') as f:\n",
        "                    writer = csv.writer(f) #, quotechar = \"'\")\n",
        "                    writer.writerow([status.id_str, status.author.screen_name, status.created_at, status.extended_tweet[\"full_text\"], status.favorite_count, status.user.description, status.user.verified, status.user.followers_count, 0, [i['text'] for i in status.entities['hashtags']], 0, 'None'])\n",
        "            \n",
        "            except AttributeError:\n",
        "              if hasattr(status, 'quoted_status'):   # Check if Quote tweet\n",
        "                try:\n",
        "                  print(status.text, '\\n', [i['text'] for i in status.entities['hashtags']], status.quoted_status.full_text)\n",
        "                  \n",
        "                  # Writing status data\n",
        "                  with open(outputPath, 'a') as f:\n",
        "                    writer = csv.writer(f) #, quotechar = \"'\")\n",
        "                    writer.writerow([status.id_str, status.author.screen_name, status.created_at, status.text, status.favorite_count, status.user.description, status.user.verified, status.user.followers_count, 0, [i['text'] for i in status.entities['hashtags']], 1, status.quoted_status.full_text])\n",
        "                \n",
        "                except:\n",
        "                  print(status.text, '\\n', [i['text'] for i in status.entities['hashtags']], 'None')\n",
        "                  \n",
        "                  # Writing status data\n",
        "                  with open(outputPath, 'a') as f:\n",
        "                    writer = csv.writer(f) #, quotechar = \"'\")\n",
        "                    writer.writerow([status.id_str, status.author.screen_name, status.created_at, status.text, status.favorite_count, status.user.description, status.user.verified, status.user.followers_count, 0, [i['text'] for i in status.entities['hashtags']], 0, 'None'])\n",
        "          return True\n",
        "\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def on_error(self, status_code):\n",
        "        print >> sys.stderr, 'Error:', status_code\n",
        "        return True \n",
        "\n",
        "    def on_timeout(self):\n",
        "        print >> sys.stderr, 'Timeout.'\n",
        "        return True \n",
        "\n",
        "# Writing csv titles\n",
        "with open(outputPath, 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    # writer.writerow(['tweet_id', 'user', 'created_on', 'tweet_text', 'fav_count', 'user_description', 'user_verified', 'user_follower_count', 'is_retweet', 'hashtags'])\n",
        "    writer.writerow(['tweet_id', 'user', 'created_on', 'tweet_text', 'fav_count', 'user_description', 'user_verified', 'user_follower_count', 'is_retweet', 'hashtags', 'is_quote', 'quote_text'])\n",
        "\n",
        "streamingAPI = tweepy.streaming.Stream(auth, CustomStreamListener())\n",
        "streamingAPI.filter(track=searchTerm, languages=['en'], is_async=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 849 ms (started: 2021-04-24 13:58:16 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cep10uIno8U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}